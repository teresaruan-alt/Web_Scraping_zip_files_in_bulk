{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping - Monthly Trip data in Bulk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dependencies\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url= 'https://s3.amazonaws.com/tripdata/index.html'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect page to find which tags or classes where information reside\n",
    "1) Right-click and inspect index.html\n",
    "\n",
    "2) Go to \"Network\" tab, make sure \"All\" is selected on ribbon\n",
    "\n",
    "3) Click \"index.html\" => go to section \"Request Headers\"\n",
    "\n",
    "4) Copy element \"User-Agent\" from the bottim section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "response= requests.get(url, headers={\n",
    "    \"User-Agent\" : \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.83 Safari/537.36\"    \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      "<head>\n",
      "<!--\r\n",
      "\r\n",
      "  Amazon S3 Bucket listing.\r\n",
      "\r\n",
      "\r\n",
      "  Copyright (C) 2008 Francesco Pasqualini\r\n",
      "\r\n",
      "      This program is free software: you can redistribute it and/or modify\r\n",
      "      it under the terms of the GNU General Public License as published by\r\n",
      "      the Free Software Foundation, either version 3 of the License, or\r\n",
      "      (at your option) any later version.\r\n",
      "\r\n",
      "      This program is distributed in the hope that it will be useful,\r\n",
      "      but WITHOUT ANY WARRANTY; without even the implied warranty of\r\n",
      "      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\r\n",
      "      GNU General Public License for more details.\r\n",
      "\r\n",
      "      You should have received a copy of the GNU General Public License\r\n",
      "      along with this program.  If not, see <http://www.gnu.org/licenses/>.\r\n",
      "\r\n",
      "  -->\n",
      "<!--\r\n",
      "\r\n",
      "  Modified by Nolan Lawson!  (http://nolanlawson.com).  I'm keeping the spirit of the\r\n",
      "  GPL alive by issuing this with the same license!\r\n",
      "\r\n",
      "  -->\n",
      "<title>Bucket loading...</title>\n",
      "<link href=\"//netdna.bootstrapcdn.com/bootstrap/2.3.2/css/bootstrap.min.css\" rel=\"stylesheet\"/>\n",
      "<style>\r\n",
      "        .hide-while-loading {\r\n",
      "          display:none;\r\n",
      "        }\r\n",
      "        .i-expand-collapse {\r\n",
      "          opacity: 0.3;\r\n",
      "        }\r\n",
      "        .i-file-or-folder {\r\n",
      "          margin-right: 4px;\r\n",
      "        }\r\n",
      "      </style>\n",
      "<script src=\"//ajax.googleapis.com/ajax/libs/jquery/1.8.3/jquery.min.js\"></script>\n",
      "<script src=\"//cdnjs.cloudflare.com/ajax/libs/handlebars.js/1.1.2/handlebars.min.js\"></script>\n",
      "<script src=\"//cdnjs.cloudflare.com/ajax/libs/moment.js/2.4.0/moment.min.js\"></script>\n",
      "</head>\n",
      "<body>\n",
      "<div class=\"container\">\n",
      "<h1 id=\"h1-title\">Bucket loading...</h1>\n",
      "<table class=\"hide-while-loading table table-striped\">\n",
      "<thead>\n",
      "<tr>\n",
      "<th>Name</th>\n",
      "<th>Date Modified</th>\n",
      "<th>Size</th>\n",
      "<th>Type</th>\n",
      "</tr>\n",
      "</thead>\n",
      "<tbody id=\"tbody-content\">\n",
      "</tbody>\n",
      "</table>\n",
      "</div>\n",
      "<script id=\"file-or-folder\" type=\"text/x-handlebars-template\">\r\n",
      "    <tr>\r\n",
      "      {{#if isFolder}}\r\n",
      "        <td><i class=\"icon-chevron-down i-expand-collapse\" style=\"margin-left:calc(({{numLevels}} - 1) * 16px)\");></i><i class=\"icon-folder-open i-file-or-folder\" style=\"margin-left:4px;\"></i>\r\n",
      "        {{simpleFilename}}</td>\r\n",
      "      {{else}}\r\n",
      "        <td><i class=\"icon-file i-file-or-folder\"  style=\"margin-left:calc(({{numLevels}} * 16px) + 4px);\"></i>\r\n",
      "        <a href=\"{{url}}\">{{simpleFilename}}</a></td>\r\n",
      "      {{/if}}\r\n",
      "      <td>{{friendlyLastModified}}</td>\r\n",
      "\r\n",
      "      <td>{{friendlySizeName}}</td>\r\n",
      "      <td>{{type}}</td>\r\n",
      "    </tr>\r\n",
      "  </script>\n",
      "<script>\r\n",
      "    (function($){\r\n",
      "      \"use strict\";\r\n",
      "      var FOLDER_PATTERN = new RegExp('_\\\\$folder\\\\$$');\r\n",
      "      var TYPE_PATTERN = new RegExp('\\\\.([^\\\\.\\\\s]{1,10})$');\r\n",
      "        var KB = 1024;\r\n",
      "        var MB = 1000000;\r\n",
      "        var GB = 1000000000;\r\n",
      "\r\n",
      "    // replace last /index.html to get bucket root\r\n",
      "      var bucketUrl = document.location.href.replace(/\\/[^\\/]+$/, '');\r\n",
      "        var compiledTemplate;\r\n",
      "\r\n",
      "    // return e.g. 1.2KB, 1.3MB, 2GB, etc.\r\n",
      "      function toFriendlySizeName(size){\r\n",
      "        if (size === 0) {\r\n",
      "          return '';\r\n",
      "        } else if (size < KB) {\r\n",
      "          return size + ' B';\r\n",
      "        } else if (size < MB) {\r\n",
      "          return (size / KB).toFixed(0) + ' KB';\r\n",
      "        } else if (size < GB) {\r\n",
      "          return (size / MB).toFixed(2) + ' MB';\r\n",
      "        }\r\n",
      "        return (size / GB).toFixed(2) + ' GB';\r\n",
      "      }\r\n",
      "\r\n",
      "\r\n",
      "      // POJO describing a file or a folder\r\n",
      "      function FileOrFolder(lastModified, etag, size, key){\r\n",
      "        var self = this;\r\n",
      "\r\n",
      "        self.lastModified = lastModified;\r\n",
      "        self.etag = etag;\r\n",
      "        self.size = size;\r\n",
      "        self.key = key;\r\n",
      "\r\n",
      "        // init logic\r\n",
      "        self.isFolder = FOLDER_PATTERN.test(self.key);\r\n",
      "        self.filename = self.isFolder ? self.key.replace(FOLDER_PATTERN,'') : self.key;\r\n",
      "        self.url = bucketUrl + '/' + self.key;\r\n",
      "        self.levels = self.filename.split('/');\r\n",
      "        self.numLevels = self.levels.length;\r\n",
      "        self.simpleFilename = self.levels[self.numLevels - 1];\r\n",
      "        self.friendlySizeName = toFriendlySizeName(parseInt(self.size,10));\r\n",
      "        var foundTypes = TYPE_PATTERN.exec(self.simpleFilename);\r\n",
      "        self.type = self.isFolder ? 'Folder ' : (foundTypes ? (foundTypes[1].toUpperCase() + ' file') : 'Unknown');\r\n",
      "        self.friendlyLastModified = moment(lastModified).format('MMM Do YYYY, hh:mm:ss a');\r\n",
      "      }\r\n",
      "\r\n",
      "        function onAjaxSuccess(xml) {\r\n",
      "            var listBucketResult = $(xml).find('ListBucketResult');\r\n",
      "\r\n",
      "            // set a reasonable title instead of \"Bucket loading\"\r\n",
      "            var title = 'Index of bucket \"' + listBucketResult.find('Name').text() + '\"';\r\n",
      "            document.title = title;\r\n",
      "            $('#h1-title').text(title);\r\n",
      "\r\n",
      "            var $tbodyContent = $('#tbody-content');\r\n",
      "\r\n",
      "            // create the file or folder objects\r\n",
      "\r\n",
      "            var filesOrFolders = [];\r\n",
      "\r\n",
      "            listBucketResult.find('Contents').each(function(idx, element){\r\n",
      "\r\n",
      "                var $element = $(element);\r\n",
      "\r\n",
      "                var fileOrFolder = new FileOrFolder(\r\n",
      "                     $element.find('LastModified').text(),\r\n",
      "                     $element.find('ETag').text(),\r\n",
      "                     $element.find('Size').text(),\r\n",
      "                     $element.find('Key').text()\r\n",
      "                );\r\n",
      "\r\n",
      "                filesOrFolders.push(fileOrFolder);\r\n",
      "            });\r\n",
      "\r\n",
      "            // sort\r\n",
      "            filesOrFolders.sort(function(left, right){\r\n",
      "                if (left.levels === right.levels) {\r\n",
      "                    return 0;\r\n",
      "                } else if (left.levels < right.levels) {\r\n",
      "                    return -1;\r\n",
      "                }\r\n",
      "                return 1;\r\n",
      "            });\r\n",
      "\r\n",
      "            // fill in the rows\r\n",
      "            var str = '';\r\n",
      "            for (var i = 0; i < filesOrFolders.length; i ++) {\r\n",
      "                str += compiledTemplate(filesOrFolders[i]);\r\n",
      "            }\r\n",
      "            $tbodyContent.append(str);\r\n",
      "            $('.hide-while-loading').show();\r\n",
      "        }\r\n",
      "\r\n",
      "        $.ajax({\r\n",
      "         url: bucketUrl,\r\n",
      "         success: onAjaxSuccess\r\n",
      "        });\r\n",
      "\r\n",
      "    // compile while ajax is in progress\r\n",
      "        compiledTemplate = Handlebars.compile($('#file-or-folder').html());\r\n",
      "\r\n",
      "    })(jQuery);\r\n",
      "    </script>\n",
      "</body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "with requests.get(url) as response: \n",
    "    soup=bs(response.content, \"lxml\") ## \"html5lib\" works as well\n",
    "    print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<div class=\"container\">\n",
      "<h1 id=\"h1-title\">Bucket loading...</h1>\n",
      "<table class=\"hide-while-loading table table-striped\">\n",
      "<thead>\n",
      "<tr>\n",
      "<th>Name</th>\n",
      "<th>Date Modified</th>\n",
      "<th>Size</th>\n",
      "<th>Type</th>\n",
      "</tr>\n",
      "</thead>\n",
      "<tbody id=\"tbody-content\">\n",
      "</tbody>\n",
      "</table>\n",
      "</div>]\n"
     ]
    }
   ],
   "source": [
    "table= soup.find_all(\"div\", class_ =\"container\")\n",
    "print(table)\n",
    "\n",
    "## NOTE: \n",
    "#  class=\"hide-while-loading table table-striped\" has running with some javascript, while inspecting the UI, \n",
    "#  zip file names are resided in tag <td> <a href=\"\"> </a> </td>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move URL directory one level up \n",
    "\n",
    "--'https://s3.amazonaws.com/tripdata/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tripdata_url='https://s3.amazonaws.com/tripdata/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<html>\\n <body>\\n  <listbucketresult xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\">\\n   <name>\\n    tripdata\\n   </name>\\n   <prefix>\\n   </prefix>\\n   <marker>\\n   </marker>\\n   <maxkeys>\\n    1000\\n   </maxkeys>\\n   <istruncated>\\n    false\\n   </istruncated>\\n   <contents>\\n    <key>\\n     201306-citibike-tripdata.zip\\n    </key>\\n    <lastmodified>\\n     2018-04-30T13:18:55.000Z\\n    </lastmodified>\\n    <etag>\\n     \"b520a12de58eea58a3586f89bfcfbd9d-2\"\\n    </etag>\\n    <size>\\n     16785103\\n    </size>\\n    <storageclass>\\n     STANDARD\\n    </storageclass>\\n   </contents>\\n   <contents>\\n    <key>\\n     201307-201402-citibike-tripdata.zip\\n    </key>\\n    <lastmodified>\\n     2017-01-18T22:23:25.000Z\\n    </lastmodified>\\n    <etag>\\n     \"7b3b260b2ab2e5349320121d04bd821c-22\"\\n    </etag>\\n    <size>\\n     178262576\\n    </size>\\n    <storageclass>\\n     STANDARD\\n    </storageclass>\\n   </contents>\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_soup(tripdata_url):\n",
    "    return bs(requests.get(tripdata_url).content, \"lxml\")\n",
    "# print(get_soup(tripdata_url).prettify())\n",
    "\"\"\" \n",
    "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "<html>\n",
    " <body>\n",
    "  <listbucketresult xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\">\n",
    "   <name>\n",
    "    tripdata\n",
    "   </name>\n",
    "   <prefix>\n",
    "   </prefix>\n",
    "   <marker>\n",
    "   </marker>\n",
    "   <maxkeys>\n",
    "    1000\n",
    "   </maxkeys>\n",
    "   <istruncated>\n",
    "    false\n",
    "   </istruncated>\n",
    "   <contents>\n",
    "    <key>\n",
    "     201306-citibike-tripdata.zip\n",
    "    </key>\n",
    "    <lastmodified>\n",
    "     2018-04-30T13:18:55.000Z\n",
    "    </lastmodified>\n",
    "    <etag>\n",
    "     \"b520a12de58eea58a3586f89bfcfbd9d-2\"\n",
    "    </etag>\n",
    "    <size>\n",
    "     16785103\n",
    "    </size>\n",
    "    <storageclass>\n",
    "     STANDARD\n",
    "    </storageclass>\n",
    "   </contents>\n",
    "   <contents>\n",
    "    <key>\n",
    "     201307-201402-citibike-tripdata.zip\n",
    "    </key>\n",
    "    <lastmodified>\n",
    "     2017-01-18T22:23:25.000Z\n",
    "    </lastmodified>\n",
    "    <etag>\n",
    "     \"7b3b260b2ab2e5349320121d04bd821c-22\"\n",
    "    </etag>\n",
    "    <size>\n",
    "     178262576\n",
    "    </size>\n",
    "    <storageclass>\n",
    "     STANDARD\n",
    "    </storageclass>\n",
    "   </contents>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files: 148\n"
     ]
    }
   ],
   "source": [
    "#Declare file format to parse and append all \".zip\" files\n",
    "filetype='.zip'\n",
    "zip_file_list=[]\n",
    "dup_file = '201307-201402-citibike-tripdata.zip'\n",
    "\n",
    "\n",
    "for link in get_soup(tripdata_url).find_all('key'):\n",
    "    file_link=link.text\n",
    "    if filetype in file_link:\n",
    "#         print(file_link)\n",
    "        zip_file_list.append(file_link)\n",
    "    \n",
    "print('Total files: ' + str(len(zip_file_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['201306-citibike-tripdata.zip', '201307-201402-citibike-tripdata.zip', '201307-citibike-tripdata.zip', '201308-citibike-tripdata.zip', '201309-citibike-tripdata.zip', '201310-citibike-tripdata.zip', '201311-citibike-tripdata.zip', '201312-citibike-tripdata.zip', '201401-citibike-tripdata.zip', '201402-citibike-tripdata.zip'] ['JC-201911-citibike-tripdata.csv.zip', 'JC-201912-citibike-tripdata.csv.zip', 'JC-202001-citibike-tripdata.csv.zip', 'JC-202002-citibike-tripdata.csv.zip', 'JC-202003-citibike-tripdata.csv.zip', 'JC-202004-citibike-tripdata.csv.zip', 'JC-202005-citibike-tripdata.csv.zip', 'JC-202006-citibike-tripdata.csv.zip', 'JC-202007-citibike-tripdata.csv.zip', 'JC-202008-citibike-tripdata.csv.zip']\n"
     ]
    }
   ],
   "source": [
    "#Print Zip_file_list & Exam the list to see if any DUPLICATED or UNWANTED files\n",
    "print(zip_file_list[:10], zip_file_list[138:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total targeted files: 86\n"
     ]
    }
   ],
   "source": [
    "dup_file = '201307-201402-citibike-tripdata.zip'\n",
    "file_list =[]\n",
    "for i in zip_file_list: \n",
    "    if i.find(\"JC\"):\n",
    "        file_list.append(i)\n",
    "        \n",
    "        if i in dup_file: \n",
    "            file_list.remove(i)\n",
    "            \n",
    "print('Total targeted files: ' + str(len(file_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Bulk Files Step (1) - To .csv\n",
    "\n",
    "Loop through the file_list and download each .csv\n",
    "\n",
    "    1) Loop through the \"file_list\" \n",
    "    2) open each zip file\n",
    "    3) unzip the file\n",
    "    4) extract .csv from each zip file\n",
    "    5) remove zipped file before next iteration\n",
    "    6) print execution time \n",
    "    \n",
    "    https://docs.python.org/3/library/zipfile.html\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 7.531069 minutes\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for file in file_list:\n",
    "    \n",
    "    \"\"\"  Concatenate two variables to get each zip file's url, \n",
    "         we do this because we were unable to extract the zip \n",
    "         file url from html tag, \"<table> </table> \" \"\"\"\n",
    "    file_url = tripdata_url + file  \n",
    "    \n",
    "    #open and download files\n",
    "    with open(file, \"wb\") as openfile:\n",
    "            response = requests.get(file_url)\n",
    "            openfile.write(response.content)\n",
    "            \n",
    "    # class <zipfile.ZipFile> is for reading and writting ZIP files\n",
    "    with zipfile.ZipFile(file, \"r\") as zip_file:\n",
    "        zip_file.extractall(\"tripdata\")   \n",
    "       \n",
    "    # remove zipped file before next iteration\n",
    "    os.remove(file)\n",
    "\n",
    "elapsed_time = round(((time.time() - start_time)/60),6)\n",
    "print (\"Execution time: \" + str(elapsed_time) + \" minutes\")   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename: Standarize file names in tripdata folder\n",
    "directory = 'tripdata/'\n",
    "for file in os.listdir(directory):\n",
    "    filename = os.fsdecode(file)\n",
    "    if filename.endswith('.csv'):\n",
    "        new_filename = filename.replace('-','').replace(' ','').lower()\n",
    "#         new_filename1 = filename.replace(' ','').replace('-','_').lower()\n",
    "#         new_filename= new_filename1.strip('_')\n",
    "        os.rename(os.path.join(directory, filename), os.path.join(directory, new_filename))\n",
    "    \n",
    "# #load into DataFrames into dfs dictionary\n",
    "# directory = 'tripdata/'\n",
    "# dfs = {}\n",
    "\n",
    "# for file in os.listdir(directory):\n",
    "#     filename = os.fsdecode(file)\n",
    "#     if filename.endswith('.csv'):\n",
    "#         dfs[filename.split('.')[0]] = pd.read_csv(os.path.join(directory, filename)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Bulk Files Step (2) - to  Microsoft SQL Database\n",
    "\n",
    "Loop through the file_list and download each .csv\n",
    "\n",
    "    1) Loop through the \"file_list\" \n",
    "    2) open each zip file\n",
    "    3) unzip the file\n",
    "    4) extract .csv from each zip file\n",
    "    5) remove zipped file before next iteration\n",
    "    6) print execution time \n",
    "    7) Load into MS SQL Server Management Studio\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbConnnect = pyodbc.connect(\"Driver={SQL Server Native Client 11.0};\"\n",
    "                            \"Server=LAPTOP-BURU7IOO\\SQLSERVER2019;\"\n",
    "#                             \"Database=citibike;\"\n",
    "                            \"Trusted_Connection=yes;\"\n",
    "                            \"autocommit = True;\") # autocommit=False by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To initialize a cursor:\n",
    "dbCursor = dbConnnect.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database ='master'\n",
      "Database ='tempdb'\n",
      "Database ='model'\n",
      "Database ='msdb'\n",
      "Database ='KinetEco'\n",
      "Database ='LandonHotel'\n",
      "Database ='WideWorldImporters'\n",
      "Database ='citibike'\n"
     ]
    }
   ],
   "source": [
    "# https://www.tutorialgateway.org/python-sql-create-db/\n",
    "dbCursor.execute(\"select * from master.dbo.sysdatabases\")\n",
    "for x in dbCursor:\n",
    "    print('Database =%r'%x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_sql(\"select * from [LandonHotel].[dbo].[Guests]\",dbConnnect)\n",
    "# data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'delim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-61841fb0d95c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mupload_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tripdata'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'201306citibiketripdata'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdbCursor\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'delim' is not defined"
     ]
    }
   ],
   "source": [
    "upload_table('tripdata','201306citibiketripdata', delim, dbCursor )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_table(path, filename, delim, dbCursor):\n",
    "    \"\"\"\n",
    "    Function to upload flat file to sqlserver\n",
    "    \"\"\"\n",
    "    tbl = filename.split('.')[0]\n",
    "    cnt = 0\n",
    "    with open (path + filename, 'r') as f:\n",
    "        reader = csv.reader(f, delimiter=delim)\n",
    "        for row in reader:\n",
    "            row.pop() # can be commented out\n",
    "            row = ['NULL' if val == '' else val for val in row]\n",
    "            row = [x.replace(\"'\", \"''\") for x in row]\n",
    "            out = \"'\" + \"', '\".join(str(item) for item in row) + \"'\"\n",
    "            out = out.replace(\"'NULL'\", 'NULL')\n",
    "            query = \"INSERT INTO \" + tbl + \" VALUES (\" + out + \")\"\n",
    "            dbCursor.execute(query)\n",
    "            cnt = cnt + 1\n",
    "            if cnt % 10000 == 0:\n",
    "                dbCursor.commit()\n",
    "        dbCursor.commit()\n",
    "    print(\"Uploaded \" + str(cnt) + \" rows into table \" + tbl + \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reporting_period():\n",
    "    table_name = filename[:4] + '_' + filename[4:6] + '_tripdata'\n",
    "    as_of_date = filename[:4] + '-' + filename[4:6]\n",
    "    print(as_of_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013-06\n"
     ]
    }
   ],
   "source": [
    "filename ='201306citibiketripdata.csv'\n",
    "reporting_period()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2013-06'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path='tripdata/'\n",
    "filename ='201306citibiketripdata.csv'\n",
    "# tbl = filename.split('.')[0]\n",
    "table_name= filename.split('.')[0]\n",
    "as_of_date = filename[:4] + '-' + filename[4:6] \n",
    "# '2013-06'\n",
    "\n",
    "table_name = filename[:4] + '_' + filename[4:6] + '_tripdata'\n",
    "# '2013_06_tripdata'\n",
    "as_of_date           \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tripduration',\n",
       " 'starttime',\n",
       " 'stoptime',\n",
       " 'start station id',\n",
       " 'start station name',\n",
       " 'start station latitude',\n",
       " 'start station longitude',\n",
       " 'end station id',\n",
       " 'end station name',\n",
       " 'end station latitude',\n",
       " 'end station longitude',\n",
       " 'bikeid',\n",
       " 'usertype',\n",
       " 'birth year',\n",
       " 'gender']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(path + filename)\n",
    "list(data.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'2013-06',\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"NoneType\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-110-448d2d98c16e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"'\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"', '\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"'\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"'NULL'\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'NULL'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mquery\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"INSERT INTO \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtable_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" VALUES (\"\u001b[0m \u001b[1;33m+\u001b[0m  \u001b[0mas_of\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mout\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\")\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate str (not \"NoneType\") to str"
     ]
    }
   ],
   "source": [
    "with open (path + filename,'r') as csvfile: \n",
    "    csv_reader = csv.reader(csvfile, delimiter = \",\")\n",
    "    as_of =reporting_period()\n",
    "    as_of\n",
    "    for row in csv_reader:\n",
    "        row.pop() # can be commented out\n",
    "        row = ['NULL' if val == '' else val for val in row]\n",
    "        row = [x.replace(\"'\", \"''\") for x in row]\n",
    "        out = \"'\" + \"', '\".join(str(item) for item in row) + \"'\"\n",
    "        out = out.replace(\"'NULL'\", 'NULL')\n",
    "        query = \"INSERT INTO \" + table_name + \" VALUES (\" +  as_of + out + \")\"\n",
    "        print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_op is the dataframe that needs to be written to database and test is the table name in database and col_name1, col_name2,... are the respective column names\n",
    "dbCursor.fast_executemany = True\n",
    "for row_count in range(0, df_op.shape[0]):\n",
    "   chunk = df_op.iloc[row_count:row_count + 1,:].values.tolist()\n",
    "   tuple_of_tuples = tuple(tuple(x) for x in chunk)\n",
    "   dbCursor.executemany(\"insert into test\" + \" ([col_name1],   col_name2],[col_name3],[col_name4] values )\",tuple_of_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
